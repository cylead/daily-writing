### preface
Author:
1. Hisory of the book: courses for undergraduate students in the computer and systems engineering program and related areas and some first-year graduate students.
2. What is the coverage and depth of this book?
Somewhere in the middle: combine probability and random processes, largely avoiding a measure theoretic approach, preferring to emphasize the axioms upon which the theory is based. Also includes lots of applicaitons.
3. topics
probability ch1-4, random process ch5-9
4. Big changes in 3rd edition.

Me:
1. Who the readers should be?
Suited for different levels of engineering students, since it covers both basic and advanced topics.
2. What are the main topics and related fields?
Engineering, not math (complete measure theoretic approach)


### ch1 introduction to probability
Author:
1. Why? Is anything truly random and if so how does one differentiate between the truly random and that which, because of a lack of information, is treated as random but really isn't?"
two extreme perspective and author's idea: we have to use probabilistic models because we do not know, cannot calculate, or cannot measure all the forces contributing to an effect.

2. Different types of probability
probability as intuition, probability as the ratio of favoraable to Total Outcomes (classical theory), probability as a measure of frequency of occurence, probability based on an Axiomatic theory 
3. Misunderstanding: conditional probability and probability,
4. Definition of experiment and set: the sample (description) space is defined after the random experiment.

Me:
1. How to easily understand the measure theory part?
2. Misunderstanding about probability.
the conditional probability is related to the why problem above, it is also related to why we need lots of data to fit a model. From the perspective of "relative frequency" sense of view, if we take all the complexity into consideration, a sample will only be comparable with it self. This is a reason why we need the axioms.
This also shows that causality is not considered in the traditional probability frame work.
1. Why do we put uncertainty into consideration? Is it mandatory in the applications?

### ch3
introduction: crucial

FRV: example: waveform decoding, 
it reminds me that many probabilistic methods (eg. probabilistic graph model) are just cases of function of random variables.

Is anything truly random and if so how does one differentiate between the truly random and that which, because of a lack of information, is treated as random but really isn't?