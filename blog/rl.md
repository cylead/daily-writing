1. **environment**: rules/programs (eg. games) or real environments (eg. autonomous driving)
2. **state** $s$: a summary of the environment
   1. (*how*): the current state can be partial observation (eg, lol) or full observation (eg. chess)
3. **agent**: decision maker in the environment
4. **action** $a$: decision made by the agent
   1. action space $\mathcal{A}$: the set of all possible actions
5. **policy** $\pi(a|s)$: the strategy of decision making based on the observed state 
6. **reward** $r$: a number returned by the environment after the implementation of an action.
7. **state transition**: after an action, the environment changes from state $s$ to $s'$
   1. **state transition probability** $p_t(s'|s, a) = \mathbb{P}(S'_{t+1}=s'|=S_{t}=s,A_t=a)$
   2. (*how*) randomness: comes from the randomness of the environment
8. **Markov decision process** MDP
9.  **episode**
10. **trajectory** $(s_1, a_1, r_1, s_2, a_2, r_2, ...)$
11. **(discounted) return**
12. **action-value function** 
    1.  **optimal action-value function**
13. **optimal Bellman equation**
14. **state-value function**

The Completionists 
lalazy
Summer Bucketeers 
synony
researchgate
